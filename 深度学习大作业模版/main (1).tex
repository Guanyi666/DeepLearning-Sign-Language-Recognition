%%%%%%%%%%%%%%%%%%%%%%%%  文档配置  %%%%%%%%%%%%%%%%%%%%%%%%

% 加载 config 类，参数传递给 ctexreport 和 geometry
\documentclass[report, twoside, UTF8, AutoFakeBold = 1, AutoFakeSlant, zihao = -4]{config}


% 注意：config.cls 已包含 amsmath, graphicx, booktabs, multirow 等常用宏包
% 这里无需重复加载，仅需加载本文档特有的额外宏包（如有）

% 封面图片定义 (请确保 images 文件夹下有这些 logo)
\def \titlePageImages{
    \includegraphics[width=0.15\textwidth] {NWPU-logo.pdf}\\ % 校徽
    \includegraphics[width=0.25\textwidth] {NWPU-title-CN.pdf}\\ % 中文校名
    \includegraphics[width=0.25\textwidth] {NWPU-title-EN.pdf}\\ % 英文校名
}

% 文档信息定义
\def \majorTitle   {深度学习课程设计}
\def \minorTitleCN {基于双流 CNN-LSTM 融合网络的手语识别}
\def \minorTitleEN {Sign Language Recognition Based on Dual-Stream CNN-LSTM}
\def \currentDate  {\zhtoday}

\def \classificationNumber  {A0001}
\def \UDC          {}
\def \confidentialLevel   {公开}
\def \serialNumber          {0001}

% 个人信息定义 (参数：下划线长度, 字号, 标题, 内容)
\def \titlePageInfoBox{
    \infobox{6cm}{-2}{学~~~~~~~~院}{软件学院}\\
    \infobox{6cm}{-2}{专~~~~~~~~业}{软件工程}\\
    \infobox{6cm}{-2}{组~~~~~~~~名}{第7组}\\
    \infobox{6cm}{-2}{姓~~~~~~~~名}{朱靖轩(组长)}\\
    \infobox{6cm}{-2}{学~~~~~~~~号}{2023303017}\\
    \infobox{6cm}{-2}{指导教师}{徐韬}\\
}

%%%%%%%%%%%%%%%%%%%%%%%%  文档开始  %%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

% 封面
\CoverPage
    {empty} % 封面类型：both、left、right、empty
    {1} % 大标题字号
    {2} % 中文标题字号
    {-2} % 英文标题字号

%%%%%%%%%%%%%%%%%%%%%  正文前页眉页脚  %%%%%%%%%%%%%%%%%%%%%%

% 页眉（关闭页眉务必将页眉类型设为empty）
\Header
    {common} % 页眉类型：common、publish、empty
    {1pt} % 上分隔线宽度
    {1pt} % 两线距离
    {0.5pt} % 下分割线宽度
    {} % 页眉左自定义内容（文本或图片）
    {\includegraphics[width=0.15\textwidth]{NWPU-title-CN.pdf}} % 页眉中自定义内容（文本或图片）
    {} % 页眉右自定义内容（文本或图片）

%============================================%

% 页脚（关闭页脚务必将页脚类型设为empty）
\Footer
    {common} % 页脚类型：common、publish、empty
    {0pt} % 上分隔线宽度
    {0pt} % 两线距离
    {0pt} % 下分割线宽度
    {} % 页脚左自定义内容（文本或图片）
    {\thepage} % 页脚中自定义内容（文本或图片）
    {} % 页脚右自定义内容（文本或图片）

%============================================%

% 页数样式 参数：#1起始页数
\SetRomanPageNumber{1} % 设置罗马数字页码
% \setArabicPageNumber{1} % 设置阿拉伯数字页码

% --- 中文摘要 ---
% 注意：必须在环境开始前定义关键词，否则因作用域问题在环境结束时无法读取
\def\keywordsCN{手语识别，CNN-LSTM，MediaPipe，数据增强，深度学习}

\begin{abstractCN}[-2]
    本文旨在解决中国手语识别中的动态时序建模问题。针对现有数据集背景单一、缺乏针对性的问题，构建了基于日常核心词汇的自建数据集。文中详细阐述了基于 MediaPipe 的手部关键点提取流程，设计了基于能量阈值的自适应动作分割算法，并提出了包含时间拉伸、高斯扰动等策略的时空数据增强方案。后续将基于双流 CNN-LSTM 网络验证该数据集及预处理方案的有效性。
\end{abstractCN}

% --- 英文摘要 ---
\def\keywordsEN{Sign Language Recognition, CNN-LSTM, MediaPipe, Data Augmentation, Deep Learning}

\begin{abstractEN}[-2]
    This paper aims to address the dynamic temporal modeling problem in Chinese Sign Language (CSL) recognition.
    To overcome the limitations of existing datasets, such as simple backgrounds and lack of specificity, a self-built dataset based on daily core vocabularies is constructed.
    The paper details the hand keypoint extraction pipeline based on MediaPipe, designs an adaptive action segmentation algorithm based on energy thresholds, and proposes a spatio-temporal data augmentation scheme including time warping and Gaussian jittering.
    Future work will verify the effectiveness of the dataset and preprocessing scheme based on the dual-stream CNN-LSTM network.
\end{abstractEN}

% --- 目录 ---
% 参数：行距, 标题名称
\contentPage{1.5}{目~~~~录}
\contentpageOfFigures{1.5}{图目录}
\contentpageOfTables{1.5}{表目录}



%%%%%%%%%%%%%%%%%%%%%  正文页眉页脚  %%%%%%%%%%%%%%%%%%%%%%

% 页眉（关闭页眉务必将页眉类型设为empty）
\Header
    {common} % 页眉类型：common、publish、empty
    {1pt} % 上分隔线宽度
    {1pt} % 两线距离
    {0.5pt} % 下分割线宽度
    {基于双流 CNN-LSTM 融合网络的手语识别} % 页眉左自定义内容（文本或图片）
    {} % 页眉中自定义内容（文本或图片）
    {\currentChapterInfo} % 页眉右自定义内容（文本或图片）

%============================================%

% 页脚（关闭页脚务必将页脚类型设为empty）
\Footer
    {common} % 页脚类型：common、publish、empty
    {0pt} % 上分隔线宽度
    {0pt} % 两线距离
    {0pt} % 下分割线宽度
    {} % 页脚左自定义内容（文本或图片）
    {\thepage} % 页脚中自定义内容（文本或图片）
    {} % 页脚右自定义内容（文本或图片）

%============================================%

% 页数样式 参数：#1起始页数
% \setRomanPageNumber{1} % 设置罗马数字页码
\SetArabicPageNumber{1} % 设置阿拉伯数字页码
% 重置页码为阿拉伯数字 (1, 2, 3...)
\SetArabicPageNumber{1}

%%%%%%%%%%%%%%%%%%%%%%%  启用水印  %%%%%%%%%%%%%%%%%%%%%%%%

\imageWatermark % 图片水印
    {0} % 旋转角度
    {0.8} % 放缩倍率
    {0.03} % 透明度 在0-1之间调整
    {images/logos/NWPU-logo.eps} % 图片路径


% ================= 正文章节内容 =================

\chapter{引言}
\section{研究背景与意义}
[待补充：介绍手语识别的社会意义，以及深度学习在该领域的应用现状...]

\section{国内外研究现状}
[待补充：分析 CNN、LSTM、Transformer 等模型在 SLR 领域的应用...]

\section{本文主要工作}
[待补充：简述本文的创新点和主要贡献...]

%=========数据集采集与预处理=======================%
\chapter{数据集获取与预处理}
\label{chap:dataset}

\section{任务背景与数据集构建动机}
在计算机视觉领域，\textbf{手语识别（Sign Language Recognition, SLR）}与传统的\textbf{手势识别（Gesture Recognition）}存在本质区别。手势识别通常关注静态的手部姿态（如“握拳”、“V手势”）或简单的短时指令，往往缺乏语言学属性。而手语是一门完备的视觉语言，具有复杂的语法结构、丰富的词汇语义以及长时序的动态演变特性。一个完整的手语动作不仅依赖于手型，还高度依赖于手部的运动轨迹、空间位置变化以及双手间的协同配合。

尽管目前存在如 NVGesture、EgoGesture 等手势数据集，但针对\textbf{中国手语（Chinese Sign Language, CSL）}的高质量公开数据集相对稀缺。现有的 CSL 数据集大多采集于受控的实验室环境，背景单一且缺乏多样性的光照和视角变化，难以满足模型在真实场景下的泛化需求。此外，针对特定课程任务的小样本词汇训练集更是空白。

鉴于此，为了构建一个既符合中国手语语言习惯，又具有一定鲁棒性的验证基准，本研究决定自主搭建手语视频采集系统，构建专用的手语数据集。这不仅能够保证数据的针对性，也为后续验证双流 CNN-LSTM 融合网络在动态时序建模上的有效性提供了数据基础。

\section{数据集的采集与分布}
\label{sec:dataset_selection}
本项目依据《中国手语》标准词汇，选取了日常交流中频率最高的 6 个核心词汇作为识别对象，分别为“好”、“他”、“早上”、“谢谢”、“很”和“你”。

数据采集过程邀请了多位志愿者参与，尽可能覆盖不同的打手语习惯（如动作幅度、速度）。视频录制设备采用标准 RGB 摄像头，分辨率为 $1920 \times 1080$，帧率保持在 30fps。最终经过人工清洗，剔除模糊严重或动作不完整的片段，共获取有效原始样本 \textbf{318} 条。各类别的样本分布如表 \ref{tab:original_samples} 所示。

\begin{table}[htbp]
    \centering
    \caption{自建原始数据集样本数量分布}
    \label{tab:original_samples}
    \begin{tabular}{ccccccc|c}
        \toprule
        \textbf{手语词汇} & \textbf{好} & \textbf{他} & \textbf{早上} & \textbf{谢谢} & \textbf{很} & \textbf{你} & \textbf{总计} \\
        \midrule
        样本数量 & 49 & 88 & 48 & 36 & 49 & 48 & 318 \\
        \bottomrule
    \end{tabular}
\end{table}

\section{基于 MediaPipe 的动态特征提取}
\label{sec:feature_extraction}
为了从冗余的视频像素中提取紧凑且富有判别力的语义信息，本研究设计了基于骨骼关键点的特征提取流水线。

\subsection{手部关键点提取与空间拓扑构建}
我们利用 \textbf{MediaPipe Hands} 框架对视频序列进行逐帧解析。相较于传统的 OpenPose，MediaPipe 在移动端和轻量级设备上具有更高的推理效率。
\begin{enumerate}
    \item \textbf{检测配置：} 设置 \texttt{max\_num\_hands=2} 以支持双手交互动作的捕捉，并关闭 \texttt{static\_image\_mode}（设为 False），利用上一帧的检测结果指导当前帧的追踪，从而显著减少抖动并提高时序连贯性。
    \item \textbf{关键点定义：} 系统每帧输出每只手的 \textbf{21 个} 骨骼关键点坐标 $\mathbf{p} = (x, y, z)$。其中，$x, y$ 为归一化平面坐标，$z$ 为以腕关节为原点的相对深度坐标。
\end{enumerate}
为了显式地建模手部物理结构，我们基于生物学解剖特征，定义了一个 $21 \times 21$ 的邻接矩阵 $\mathbf{A}$，描述了手腕到指尖的 20 条骨骼连接。这为后续基于图结构的特征分析奠定了拓扑基础。

\subsection{基于能量阈值的自适应动作分割}
原始录制视频通常包含动作前后的预备动作（Pre-stroke）和撤回动作（Post-stroke），以及动作中间的自然停顿。为了精确截取语义动作段，我们提出了一种\textbf{基于运动能量且具备停顿容忍度（Pause-Tolerant）}的自动分割算法。

算法核心步骤如下：
\begin{enumerate}
    \item \textbf{瞬时能量计算：} 定义第 $t$ 帧的运动能量 $E_t$ 为双手所有关键点相对于上一帧的位移向量的 $L_2$ 范数之和：
    \begin{equation}
        E_t = \sum_{h \in \{L, R\}} \sum_{i=1}^{21} \| \mathbf{p}_{h,i}^{(t)} - \mathbf{p}_{h,i}^{(t-1)} \|_2^2
    \end{equation}
    其中 $\mathbf{p}_{h,i}^{(t)}$ 表示第 $t$ 帧第 $h$ 只手第 $i$ 个关键点的坐标。

    \item \textbf{能量平滑：} 为消除检测噪声引起的能量抖动，对 $E_t$ 序列进行窗口大小为 3 的移动平均平滑。

    \item \textbf{自适应边界判定：} 设定自适应阈值 $\tau = 0.5 \cdot \text{mean}(E) + \epsilon$。
    \begin{itemize}
        \item 当 $E_t > \tau$ 时，判定动作开始。
        \item 当 $E_t < \tau$ 时，并不立即判定结束，而是启动计数器 $C_{pause}$。只有当连续静止帧数 $C_{pause} > \text{max\_pause\_len}$（本实验设为 25 帧）时，才判定动作真正结束。
    \end{itemize}
\end{enumerate}
这一机制有效解决了复杂手语动作中因短暂亦扬顿挫而被错误切分为多个片段的问题。

\subsection{时序统计特征向量构建}
为了降低计算复杂度并保留动作的统计分布特性，我们将原始的 $21 \times 3$ 坐标点压缩为高层的统计特征。对于每一个动作区间，逐帧提取 12 维特征向量 $V_t$：
\begin{equation}
    V_t = [\mu_L, \sigma_L^2, \mu_R, \sigma_R^2]^\top \in \mathbb{R}^{12}
\end{equation}
其中 $\mu \in \mathbb{R}^3$ 和 $\sigma^2 \in \mathbb{R}^3$ 分别代表手部关键点群在 $x, y, z$ 轴上的均值和方差。均值特征反映了手部在画面中的\textbf{绝对位置}轨迹，而方差特征则隐含了手势的\textbf{张开程度和形态变化}信息。

\section{时序规范化与多策略数据增强}
\label{sec:data_augmentation}

\subsection{时序归一化}
由于不同志愿者打手语的语速存在差异，导致提取出的动作序列长度不一。为满足神经网络固定输入维度的要求，本研究采用\textbf{重采样技术}将所有样本的时序长度统一为 $T=30$ 帧。
\begin{itemize}
    \item 对于短序列（$L < 30$），采用\textbf{末帧填充（Padding）}策略，保持动作语义的完整性。
    \item 对于长序列（$L > 30$），采用\textbf{线性插值采样}，保证关键动作帧不丢失。
\end{itemize}

\subsection{时空数据增强机制}
深度学习模型的性能高度依赖于数据的规模与多样性。考虑到自建数据集仅有 318 个样本，极易导致模型过拟合。因此，本研究设计了一套包含四种变换策略的\textbf{时空数据增强（Spatio-Temporal Augmentation）}方案，旨在模拟真实应用场景中的各种干扰因素。通过不同随机种子的组合，将数据集扩充至 \textbf{2862} 条（扩增倍数 $9\times$）。具体增强方法如下：

\subsubsection{1. 时间拉伸与压缩 (Time Warping)}
模拟不同用户语速的快慢差异。通过对时序索引 $t$ 进行非线性变换 $t' = \alpha t + \beta$，再通过插值重新生成特征序列。这迫使模型学习动作的内在演变规律，而非简单记忆帧与帧之间的绝对对应关系，从而提升对语速变化的鲁棒性。

\subsubsection{2. 坐标高斯噪声扰动 (Gaussian Jittering)}
模拟摄像头成像噪声或 MediaPipe 检测的微小抖动。在每个关键点特征 $v_{t,i}$ 上叠加高斯噪声 $\epsilon \sim \mathcal{N}(0, \sigma^2)$：
\begin{equation}
    v'_{t,i} = v_{t,i} + \epsilon
\end{equation}
这不仅增强了模型对输入噪声的容忍度，也相当于在特征空间中对样本分布进行了平滑，防止模型陷入局部极小值。

\subsubsection{3. 时间平移 (Time Shift)}
模拟动作检测模块可能存在的边界定位误差（即动作开始/结束时间的判定偏移）。通过将整个特征序列沿时间轴向前或向后平移 $\Delta t$ 帧，并在空缺处进行补零或边缘填充。这训练了模型在非严格对齐的情况下识别关键动作模式的能力。

\subsubsection{4. 空间旋转变换 (Spatial Rotation)}
模拟摄像头拍摄角度的偏差或用户手掌朝向的多样性。构建二维旋转矩阵 $R(\theta)$ 对手部 $x, y$ 坐标特征进行变换：
\begin{equation}
    \begin{bmatrix} x' \\ y' \end{bmatrix} =
    \begin{bmatrix}
    \cos\theta & -\sin\theta \\
    \sin\theta & \cos\theta
    \end{bmatrix}
    \begin{bmatrix} x \\ y \end{bmatrix}
\end{equation}
其中旋转角度 $\theta$ 在一定范围内随机采样（如 $[-15^\circ, 15^\circ]$）。这极大地提升了模型对视角变化的泛化能力。

图 \ref{fig:augmentation_demo} 展示了在原始手语关键点序列的基础上，经过不同数据增强策略处理后，右手食指指尖在 X 轴方向上的轨迹变化情况。原始轨迹通常存在轻微抖动、不规则波动或由于采集环境造成的噪声；而通过加入 \textbf{时序平滑}、\textbf{随机扰动}、\textbf{时间尺度拉伸/压缩}、\textbf{空间仿射变换} 等增强方式，可以有效模拟不同使用者的手势差异、采集设备的轻微偏移，以及动作执行速度的变化。对比图中可以观察到：

\begin{enumerate}
    \item \textbf{原始轨迹}：数值分布较为集中，但局部波动明显。
    \item \textbf{平滑增强后轨迹}：去除了高频噪声，整体走势更加平稳，有利于模型捕捉动作的主趋势。
    \item \textbf{随机扰动增强后轨迹}：在主轨迹基础上加入轻微随机偏移，增强模型对个体差异的鲁棒性。
    \item \textbf{时间拉伸/压缩增强后轨迹}：轨迹走势一致，但在时序维度上被重新采样，模拟不同速度的动作执行方式。
    \item \textbf{空间变换增强后轨迹}：整体曲线形状保持一致，但位置有小幅平移或缩放，用于模拟摄像头角度与距离变化。
\end{enumerate}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{image.png}
    \caption{手语关键点数据增强效果对比 (右手食指指尖 X 坐标轨迹)}
    \label{fig:augmentation_demo}
\end{figure}

通过这些增强方式，最终得到的轨迹在保持动作语义不变的前提下显著增加了样本的多样性，有助于模型提升对实际复杂场景中手语动作的泛化能力。

综上所述，通过上述严谨的数据采集、精细的特征工程以及全面的数据增强，我们构建了一个高质量、抗干扰能力强的手语数据集，为后续模型的训练奠定了坚实基础。

%==============双流=============================%
\chapter{双流 CNN-LSTM 融合网络}
\label{chap:dual_stream}

手语识别（Sign Language Recognition, SLR）本质上是一个复杂的细粒度时空建模问题。不同于静态手势识别，手语包含连续的动态轨迹、手型变化以及手指间的拓扑关系。在本研究中，我们从单纯的视觉特征映射出发，经历了三个阶段的迭代，逐步深入挖掘数据的时空属性，最终构建了稳健的双流融合网络。

\section{模型迭代与架构演进}

\subsection{第一阶段：基于 Conv2D 的伪图像特征映射 (V1.0)}
在项目的初期探索阶段，受计算机视觉领域迁移学习的启发，我们尝试将动态的时间序列问题转化为静态的图像分类问题。

\vspace{0.5em}
\noindent\textbf{数据流与维度重构}

原始输入数据 $X$ 为 $T=30$ 帧的坐标序列，特征维度 $F=126$（包含左右手各21个关键点的 $x,y,z$ 坐标）。为了适配经典的二维卷积神经网络（Conv2D），我们采用了“伪图像”构建策略：
\begin{equation}
    \tilde{X} = \text{Tile}(\text{ExpandDims}(X, -1), [1, 1, 3]) \in \mathbb{R}^{30 \times 126 \times 3}
\end{equation}
即通过在通道维度上的复制，强制构建出 $(30, 126, 3)$ 的张量，模拟 RGB 图像结构。模型架构参考了轻量级的 MobileNet 设计，引入倒残差块（Inverted Residual Block）以提取空间纹理特征。

\vspace{0.5em}
\noindent\textbf{理论缺陷与实验失效}

尽管该模型可以运行，但在逻辑上存在致命缺陷。Conv2D 的池化操作，特别是最终的全局平均池化（Global Average Pooling），执行了如下计算：
\begin{equation}
    y = \frac{1}{T \times F} \sum_{i=1}^{T} \sum_{j=1}^{F} \phi(x)_{i,j}
\end{equation}
该操作将时间轴 $T$ 上的所有信息压缩为一个标量，导致动作的时序演变（Temporal Evolution）完全丢失。例如，“手从左移向右”和“手从右移向左”在经过全局平均后会产生极相似的特征值。实验结果证实，该模型无法区分轨迹相反但空间分布相似的动作，且对过拟合缺乏有效的抑制手段。

\subsection{第二阶段：基于 Conv1D-LSTM 的时空级联架构 (V2.0)}
针对 V1.0 丢失时序信息的痛点，第二阶段的模型回归数据的物理本质，采用“先局部空间提取，后全局时序建模”的级联架构。

\vspace{0.5em}
\noindent\textbf{时空特征提取机制}

我们首先利用一维卷积（Conv1D）捕捉帧内的空间拓扑特征。对于时间步 $t$ 的输入向量 $x_t$，卷积输出 $z_t$ 表示手指间的局部几何关系：
\begin{equation}
    z_t = \text{ReLU}(\text{Conv1D}(x_t, k=3))
\end{equation}
随后，特征序列被送入双向长短时记忆网络（Bi-LSTM）。Bi-LSTM 通过前向和后向两个状态向量，能够同时利用过去和未来的上下文信息，从而理解动作的起止逻辑与连贯性。

\vspace{0.5em}
\noindent\textbf{非平衡数据对抗策略}

针对部分手语词汇样本稀缺的问题，我们在交叉熵损失函数中引入了动态类别权重（Class Weights）。对于类别 $c$，其权重 $w_c$ 与样本数量 $n_c$ 成反比：
\begin{equation}
    L = - \sum_{c=1}^{C} \frac{N}{C \cdot n_c} y_c \log(\hat{y}_c)
\end{equation}
这一策略迫使模型更加关注少样本类别（如 "thank\_you"），避免被多数类主导。

\vspace{0.5em}
\noindent\textbf{局限性分析——数据泄露与噪声干扰}

虽然 V2.0 在训练集表现尚可，但深入审计发现其存在\textbf{数据泄露（Data Leakage）}问题。由于采用了简单的随机划分（Random Split），同一采集者的不同样本被分散在训练集和验证集中。这导致模型学习到了采集者的个人体态特征（“认人”）而非手语动作特征，导致跨用户泛化能力极差。此外，LSTM 结构对序列中的非动作帧（如起手准备、放下）较为敏感，容易被这些噪声帧干扰核心语义的判断。

\section{最终方案：双流 CNN-LSTM 融合网络}
为了解决单一数据流难以兼顾“动态轨迹”与“静态手型”的问题，我们提出了基于双流（Two-Stream）架构的最终方案。该架构包含两个并行分支，模拟了人类视觉系统处理动作和物体细节的互补机制。

\subsection{动态流分支 (Dynamic Stream)——捕捉运动过程}
该分支负责“看视频”，即理解动作的发生过程。

\vspace{0.5em}
\noindent\textbf{输入：} 完整的时序坐标序列 $X_{seq} \in \mathbb{R}^{30 \times 126}$。

\noindent\textbf{网络结构：} 采用两层堆叠的 Conv1D（Filter: 64 $\to$ 128）提取高阶时空特征，配合 MaxPooling 降低维度，最后接入 128 单元的 Bi-LSTM。

\noindent\textbf{功能：} 这种设计使其对动作的方向、速度和连贯性高度敏感，能够准确识别如“从早到晚”、“向左向右”等具有明显轨迹特征的手语。

\subsection{静态流分支 (Static Stream)——锁定关键形态}
该分支负责“看照片”，即在运动模糊或微小幅度下锁定手部形状。

\vspace{0.5em}
\noindent\textbf{输入：} 静态特征向量 $X_{stat} \in \mathbb{R}^{126}$，代表动作的整体统计特征或关键帧特征。

\noindent\textbf{网络结构：} 由多层全连接层（Dense: 128 $\to$ 64 $\to$ 64）构成深度神经网络（DNN）。

\noindent\textbf{功能：} 该分支不依赖时间依赖性，专注于分析手势的空间几何形状（如大拇指是否翘起、食指是否弯曲）。对于动作幅度极小（如“谢谢”中的轻微指关节弯曲），静态流能提供关键的判别依据，弥补了 LSTM 在微小动作上可能出现的“视而不见”。

\subsection{特征融合与性能突破}
两个分支提取的特征向量在融合层（Fusion Layer）进行拼接（Concatenation），形成包含多模态信息的联合特征向量 $Z$：
\begin{equation}
    Z = \text{BiLSTM}(X_{seq}) \oplus \text{Dense}(X_{stat}) \in \mathbb{R}^{128+64}
\end{equation}
最终，通过 Dropout (0.5) 进行正则化并经由 Softmax 输出分类概率。

\begin{figure}[htbp]
    \centering
    % 请确保图片已放入项目文件夹下的 images/ 目录中
    \includegraphics[width=0.9\linewidth]{images/image3.1.png}
    \caption{修正后模型在训练集与测试集下准确度随训练轮数变化曲线}
    \label{fig:training_acc_curve}
\end{figure}

实验结果显示，在修正了数据划分策略并应用双流架构后，模型在验证集上的准确率达到了 \textbf{93.75\%}。训练曲线表明，该架构在第 180 轮左右达到最优收敛，且 Loss 下降平稳，未出现明显的过拟合震荡。混淆矩阵进一步证实，模型在易混淆的动作（如 "he" 和 "you"）之间建立了清晰的决策边界，证明了动静特征融合策略的有效性。




\chapter{双流 CNN-LSTM 融合网络底层结构设计}

本章将详细阐述双流 CNN-LSTM 融合网络的底层架构设计。该模型通过融合空间特征提取与时序依赖建模，旨在解决手语识别任务中手势形态变化与动态时序演变的双重挑战。

\section{网络总体架构}

为了充分捕捉手语动作中的静态手势特征与动态时序信息，本研究设计了一种双流（Dual-Stream）网络架构。该架构由两个并行的处理分支组成：\textbf{空间特征流（Spatial Stream）}和\textbf{时序特征流（Temporal Stream）}。两个分支分别提取手部形态的空间表征与动作演变的时序依赖，最终通过特征融合模块进行联合决策。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{images/dual_stream_arch} % 请确保 images 文件夹下有此图片
    \caption{双流 CNN-LSTM 融合网络总体架构示意图}
    \label{fig:dual_stream_arch}
\end{figure}

总体架构如图 \ref{fig:dual_stream_arch} 所示。
具体而言，网络输入为经过预处理的固定长度为 $T=30$ 帧的手部关键点序列或图像序列。
\begin{enumerate}
    \item \textbf{空间特征流：} 采用卷积神经网络（CNN）提取每一帧图像或关键点拓扑图中的局部空间特征，捕捉手型、手指弯曲程度等静态信息。
    \item \textbf{时序特征流：} 采用长短期记忆网络（LSTM）处理由空间流输出的特征序列，或直接处理关键点位移向量，以捕捉动作的起止、快慢及轨迹变化等长时序依赖。
    \item \textbf{融合与分类：} 将两个分支的高层特征进行拼接（Concatenation）或加权求和，输入全连接层进行 Softmax 分类，输出最终的词汇预测概率。
\end{enumerate}

\section{空间特征提取模块 (CNN)}

空间特征提取模块旨在从单帧输入中提取具有判别力的手部形态特征。本研究采用一维卷积神经网络（1D-CNN）处理基于关键点的向量序列，或采用二维卷积神经网络（2D-CNN）处理手部图像 ROI。

以 1D-CNN 为例，对于时刻 $t$ 的输入特征向量 $x_t \in \mathbb{R}^{D}$（其中 $D$ 为关键点特征维度，如 $21 \times 3 = 63$），网络通过多层卷积操作提取局部相关性：
\begin{equation}
    h_t^{(l)} = \sigma \left( W^{(l)} * h_t^{(l-1)} + b^{(l)} \right)
\end{equation}
其中，$*$ 表示卷积运算，$W^{(l)}$ 和 $b^{(l)}$ 分别为第 $l$ 层的卷积核权重和偏置，$\sigma(\cdot)$ 为 ReLU 激活函数。通过堆叠多个卷积层与最大池化层（Max Pooling），网络能够逐层抽象出更高阶的手势语义特征，同时降低特征维度，减少计算冗余。

\section{时序建模模块 (LSTM)}

手语动作具有显著的时序动态特性，单纯的空间特征无法区分如“从左向右挥手”与“从右向左挥手”等轨迹相反但手型相似的动作。因此，本研究引入 LSTM 单元来建模序列的长时依赖关系。

LSTM 通过引入门控机制有效解决了传统 RNN 的梯度消失问题。其核心计算过程如下：
\begin{align}
    f_t &= \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) & (\text{遗忘门}) \\
    i_t &= \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) & (\text{输入门}) \\
    \tilde{C}_t &= \tanh(W_C \cdot [h_{t-1}, x_t] + b_C) & (\text{候选细胞状态}) \\
    C_t &= f_t \odot C_{t-1} + i_t \odot \tilde{C}_t & (\text{细胞状态更新}) \\
    o_t &= \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) & (\text{输出门}) \\
    h_t &= o_t \odot \tanh(C_t) & (\text{隐状态输出})
\end{align}
其中，$x_t$ 为 CNN 模块提取的第 $t$ 帧特征，$h_{t-1}$ 为上一时刻的隐状态，$C_{t-1}$ 为上一时刻的细胞状态，$\sigma$ 为 Sigmoid 函数，$\odot$ 表示逐元素乘积。

在本架构中，我们将 LSTM 层置于 CNN 层之后，输入为 CNN 输出的时间序列特征图。LSTM 层按时间步处理序列，最终输出最后一个时间步的隐状态 $h_T$，该状态聚合了整个动作序列的时空上下文信息。

\section{融合策略与分类层}

为了综合利用空间与时序特征，本研究采用了特征级融合（Feature-level Fusion）策略。具体操作是将 CNN 分支提取的全局静态特征向量 $F_{spatial}$ 与 LSTM 分支输出的时序特征向量 $F_{temporal}$ 进行拼接：
\begin{equation}
    F_{fused} = \text{Concat}(F_{spatial}, F_{temporal})
\end{equation}
拼接后的特征向量 $F_{fused}$ 随后通过全连接层（Fully Connected Layer）进行降维与映射，最后经过 Softmax 激活函数计算各手语类别的后验概率：
\begin{equation}
    P(y=c|X) = \frac{\exp(w_c^T F_{fused} + b_c)}{\sum_{k=1}^{K} \exp(w_k^T F_{fused} + b_k)}
\end{equation}
其中，$K$ 为手语词汇类别总数（本实验中 $K=6$）。模型通过最小化交叉熵损失函数（Cross-Entropy Loss）进行端到端训练，以优化网络参数。
%===============参数调整=====================%

\chapter{实验结果与分析}
\label{chap:experiment}

本章将详细介绍基于双流 CNN-LSTM 融合网络手语识别模型的实验过程。我们将首先说明实验的软硬件环境配置，随后采用控制变量法，详细阐述对学习率、批大小（Batch Size）、隐藏层单元数及 Dropout 正则化参数的调优过程，最后通过消融实验验证双流架构的有效性。

\section{实验环境与评价指标}

\subsection{软硬件环境配置}
本次实验基于深度学习框架 TensorFlow 2.x 与 Keras 接口搭建。考虑到模型涉及大量的时序卷积与循环神经网络计算，实验在配备 NVIDIA GPU 的高性能计算平台上进行。具体的软硬件配置如表 \ref{tab:env_config} 所示。

\begin{table}[htbp]
    \centering
    \caption{实验软硬件环境配置}
    \label{tab:env_config}
    \begin{tabular}{cc}
        \toprule
        \textbf{配置项} & \textbf{参数/版本} \\
        \midrule
        操作系统 & Windows 11 / Ubuntu 20.04 LTS \\
        编程语言 & Python 3.9 \\
        深度学习框架 & TensorFlow 2.10 (Keras Backend) \\
        关键依赖库 & MediaPipe 0.9, NumPy, OpenCV, Scikit-learn \\
        CPU & Intel Core i7-12700K \\
        GPU & NVIDIA GeForce RTX 3060 (12GB VRAM) \\
        加速环境 & CUDA 11.2, cuDNN 8.1 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{评价指标}
为了客观评价模型性能，我们采用准确率（Accuracy）、精确率（Precision）、召回率（Recall）以及 F1-score 作为主要评价指标。其中，准确率计算公式如下：
\begin{equation}
    Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}
针对多分类问题，我们将计算所有类别的加权平均（Weighted Average）指标。

\section{模型参数调优过程}
在确定了双流 CNN-LSTM 的基础架构后，超参数的选择对模型收敛速度与最终性能起着决定性作用。本研究采用**网格搜索（Grid Search）**与**控制变量法**相结合的策略，分别对优化器学习率、Batch Size、LSTM 隐藏层维度以及 Dropout 比率进行了系统性调优。

\subsection{学习率（Learning Rate）的选择}
学习率决定了梯度下降过程中参数更新的步长。学习率过大可能导致模型在极小值附近震荡甚至发散，过小则会导致收敛缓慢陷入局部最优。
我们选用 Adam 优化器，在 Batch Size 固定为 32 的前提下，对比了 0.01、0.001 和 0.0001 三个数量级的学习率。实验结果如表 \ref{tab:lr_tuning} 所示。

\begin{table}[htbp]
    \centering
    \caption{不同学习率对模型性能的影响 (Epoch=100)}
    \label{tab:lr_tuning}
    \begin{tabular}{cccc}
        \toprule
        \textbf{学习率 (LR)} & \textbf{收敛速度} & \textbf{验证集准确率 (Val Acc)} & \textbf{Loss 曲线表现} \\
        \midrule
        0.01 & 快，但不稳定 & 82.45\% & 震荡剧烈，难以收敛至最低点 \\
        \textbf{0.001} & \textbf{适中} & \textbf{93.75\%} & \textbf{平滑下降，收敛效果最佳} \\
        0.0001 & 极慢 & 88.60\% & 下降缓慢，训练耗时过长 \\
        \bottomrule
    \end{tabular}
\end{table}

实验表明，当 $LR=0.001$ 时，模型在保证收敛速度的同时获得了最高的验证集准确率。因此，最终选定初始学习率为 0.001，并配合回调函数（ReduceLROnPlateau），当验证集 Loss 在 10 个 Epoch 内不下降时，自动将学习率减半。

\subsection{批大小（Batch Size）的影响}
Batch Size 决定了单次参数更新所使用的样本数量。考虑到本数据集经过增强后约为 2862 条，数据量属中等规模。我们测试了 16, 32, 64 三种 Batch Size。

\begin{itemize}
    \item \textbf{Batch Size = 16}: 训练耗时较长，且由于单次采样样本少，Batch Normalization 层的统计量不稳定，导致验证集波动较大。
    \item \textbf{Batch Size = 64}: 训练速度最快，但在验证集上的泛化能力略有下降（Val Acc: 91.2\%），推测是陷入了尖锐极小值（Sharp Minima）。
    \item \textbf{Batch Size = 32}: 在训练稳定性和泛化性能之间取得了最佳平衡，最终验证集准确率稳定在 93\% 以上。
\end{itemize}
故本研究最终选取 **Batch Size = 32**。

\subsection{LSTM 隐藏层单元数与模型容量}
时序流分支（Temporal Stream）中的 Bi-LSTM 层是捕捉动态轨迹的核心。单元数过少会导致模型容量不足，难以拟合复杂时序；单元数过多则会显著增加计算量并引发过拟合。
我们对比了 **32, 128, 256** 三种单元设置，训练过程中的准确率变化曲线如图5-1所示。

\begin{figure}[htbp]
    \centering
    % 第一行：显示 32 和 256 的情况
    \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{images/unit32.png}
        \caption*{Unit=32: 震荡剧烈，欠拟合}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{images/unit256.png}
        \caption*{Unit=256: 收敛较慢，存在过拟合}
    \end{minipage}

    \vspace{0.5cm} % 增加垂直间距

    % 第二行：显示最佳结果 128
    \begin{minipage}{0.8\linewidth}
        \centering
        \includegraphics[width=\linewidth]{images/unit128.png}
        \caption*{Unit=128: 最佳平衡 (Val Acc: 93.75\%)}
    \end{minipage}

    \caption{不同 LSTM 隐藏层单元数下的模型收敛曲线对比}
    \label{fig:lstm_comparison}
\end{figure}

结合图 \ref{fig:lstm_comparison} 与实验数据，分析如下：
\begin{itemize}
    \item \textbf{Unit=32}：模型容量明显不足。验证集准确率（橙色虚线）呈现剧烈震荡状态，无法稳定收敛，说明过少的参数难以捕捉手语动作中复杂的时空依赖关系。
    \item \textbf{Unit=256}：虽然训练集准确率（蓝色实线）能够快速接近 1.0，但验证集准确率提升缓慢且最终低于 128 单元的配置，表现出过拟合迹象，且计算开销较大。
    \item \textbf{Unit=128}：模型在训练效率与泛化能力之间取得了最佳平衡。曲线平滑上升，最终验证集准确率稳定在 93.75\%，且未出现明显的震荡或过拟合。
\end{itemize}

因此，本研究最终锁定 Bi-LSTM 单元数为 **128**。

\subsection{Dropout 正则化参数调优}
由于数据集相对较小，防止过拟合是本次实验的关键。我们在特征融合层（Fusion Layer）之后引入 Dropout 层。
实验对比了 Dropout 率为 0.2, 0.5, 0.7 的情况：
\begin{itemize}
    \item $p=0.2$: 抑制过拟合效果不明显，训练集准确率远高于验证集（差值 > 5\%）。
    \item $p=0.7$: 信息丢失过多，导致模型难以收敛，准确率徘徊在 85\% 左右。
    \item \textbf{$\mathbf{p=0.5}$}: 效果最佳，训练集与验证集准确率曲线贴合紧密，有效缓解了过拟合现象。
\end{itemize}

\section{消融实验：验证双流架构的有效性}
为了验证第三章提出的“动静双流融合”策略的必要性，我们设计了消融实验（Ablation Study）。分别单独训练“静态流分支（仅 Dense）”和“动态流分支（仅 CNN-LSTM）”，并与完整的“双流融合网络”进行对比。

\begin{table}[htbp]
    \centering
    \caption{双流架构消融实验结果对比}
    \label{tab:ablation_study}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{模型架构} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} \\
        \midrule
        仅静态流 (Static Only) & 68.50\% & 69.2\% & 67.8\% & 0.68 \\
        仅动态流 (Dynamic Only) & 88.20\% & 89.1\% & 87.5\% & 0.88 \\
        \textbf{双流融合 (Dual-Stream)} & \textbf{93.75\%} & \textbf{94.2\%} & \textbf{93.5\%} & \textbf{0.94} \\
        \bottomrule
    \end{tabular}
\end{table}

从表 \ref{tab:ablation_study} 可以得出以下结论：
\begin{enumerate}
    \item **静态流的局限性**：仅依靠手型特征（静态流）只能达到 68.5\% 的准确率。这证实了手语识别中“轨迹”的重要性，仅凭手型无法区分如“从左往右”和“从右往左”的动作。
    \item **动态流的主导作用**：引入 LSTM 后，准确率大幅提升至 88.2\%，说明时序特征是手语识别的核心。
    \item **双流融合的互补性**：完整的双流模型相比单动态流提升了约 5.5\%。这主要得益于静态流对微小动作（如手指细微弯曲）的修正作用，证明了融合策略的有效性。
\end{enumerate}

\section{最终模型性能分析}
基于上述调参结果，最终确定的超参数组合为：\textbf{LR=0.001, Batch Size=32, LSTM Units=128, Dropout=0.5}。

在此配置下，模型在测试集上的混淆矩阵分析表明，对于动作幅度较大的词汇（如“早上”、“很”），识别准确率接近 100\%。而对于此前极易混淆的“你”和“他”（两者手型相同，仅指向轨迹不同），双流网络通过 LSTM 对轨迹的精确建模，成功将误判率降低到了 5\% 以内，圆满完成了课程设计既定的识别目标。


% ================= 以下为整合的模糊语义识别章节 =================
% ================= 模糊语义识别章节 =================
\chapter{模糊语义识别与自然语言后处理}
\label{chap:fuzzy_semantic}

手语作为一种视觉-空间语言，其自然表达具有高度的\textbf{非线性（Non-linearity）}、\textbf{协同发音（Co-articulation）}和\textbf{冗余容错}特性。这导致基于深度学习模型的孤立手语识别（Isolated Sign Language Recognition）模块通常只能输出离散的、逐词的识别结果。面对实际应用中的手势重复、顺序颠倒以及手语词汇间的语义交错，传统的“硬识别 + 直接拼接”流程无法生成自然、流畅且符合语境的中文语句。

为解决这一核心问题，本研究提出了一套\textbf{基于语义组合规则（Semantic Combination Rules）}的模糊语义识别与后处理机制，其目标是将噪声序列转化为高置信度的、符合中文表达习惯的自然语句。

\section{总体架构与模糊性挑战}
本系统的模糊语义识别模块采用严格的三阶段流水线设计，确保从离散词汇到自然语句的逻辑严谨性：
\begin{enumerate}
    \item \textbf{序列预处理}：关键语义元素提取与冗余去除。
    \item \textbf{语义上下文构建}：将词汇序列转化为结构化语义特征。
    \item \textbf{规则驱动的生成与校准}：基于语义组合规则和对话语境，生成表达并校准置信度。
\end{enumerate}

系统的核心挑战在于处理由手势识别不确定性带来的\textbf{模糊性（Fuzziness）}，即词汇多义、序列无序，以及如何基于这些不确定性特征，推理出清晰的\textbf{复合意图（Composite Intent）}。

\section{序列预处理与语义保留去冗余}
手语在连续表达中易出现词汇的重复（如强调）或混淆。我们设计的 \texttt{preprocess\_gesture\_sequence} 函数，通过\textbf{语义保留去重}策略，在保证信息完整性的前提下精简序列。

\subsection{词汇映射与标准化}
在预处理之前，系统首先对模型输出的原始词汇进行标准化映射，这是处理语义模糊性的第一步。例如，将手语识别模型输出的“她”映射为统一的“他”进行语义分析，并对“谢谢”进行标准化以识别其核心功能。核心词汇映射关系如表 \ref{tab:semantic_mapping} 所示。

\begin{table}[htbp]
    \centering
    \caption{核心手语词汇与标准化映射及语义功能}
    \label{tab:semantic_mapping}
    \begin{tabular}{cccc}
        \toprule
        \textbf{手语词汇} & \textbf{标准化语义} & \textbf{语义功能 (英文)} & \textbf{功能分类} \\
        \midrule
        谢谢 & 感谢 & gratitude & 感谢词 \\
        很 & 程度 & degree & 程度词 \\
        早上 & 早上 & time & 时间词 \\
        你, 我, 他, 她 & 你, 我, 他, 他 & pronoun / reference & 人称 / 指代词 \\
        好 & 好 & state & 状态词 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{优先级去重与语义重排序}
为了避免简单的去重操作（如 \texttt{set()}）可能导致的语义损失，我们采用基于优先级的筛选机制：
\begin{enumerate}
    \item \textbf{关键语义保留}：对具有明确意图指向的词汇（如“早上”、“谢谢”），无论其在原始序列中出现多少次，仅保留一个，以消除识别冗余，确保意图的纯粹性。
    \item \textbf{人称代词筛选}：当手势序列包含多个人称代词（如 ['你', '我']）时，系统采用预定义的语言学优先级进行选择。根据中文对话习惯，代词优先级设置为：“我” > “你” > “他/她”。系统仅保留优先级最高的代词，以明确句子的主语或宾语。
    \item \textbf{语义重排序}：预处理后的精简词汇集合，将根据中文的自然表达习惯进行重排序。例如，将时间修饰词（“早上”）置于句首，将感谢词（“谢谢”）置于问候词之前，以形成规范化的语义输入序列，为后续的规则匹配提供可信赖的基础。
\end{enumerate}

\section{语义上下文提取与意图推理}
\texttt{extract\_semantic\_context} 函数负责将预处理后的词汇序列 $S'$ 转化为结构化的\textbf{最小必要语义表示} $C$。这种表示方法是意图推理的关键。上下文 $C$ 是一个包含语义槽（Slot）的字典，例如 $C = \{ S_1 : V_1, S_2 : V_2, \dots \}$。

\subsection{语义槽的构建}
系统通过遍历 $S'$，填充以下核心语义槽：

\vspace{0.5em}
\noindent $C[\text{"pronoun"}]$：确定的主导人称代词（如“你”）。

\noindent $C[\text{"time"}]$：时间维度信息（如“早上”）。

\noindent $C[\text{"gratitude"}]$：布尔值或词汇，表示感谢意图的存在。

\noindent $C[\text{"state"}]$：状态词汇及其修饰信息（如 $\{\text{"base"}: \text{"好"}, \text{"intensity"}: 1\}$）。

\subsection{隐式语义推理}
此阶段尤其重要的是对\textbf{隐式语义（Implicit Semantics）}的推理。例如，在中文问候中，时间词往往隐含了“好”这一状态：

如果 $C[\text{"time"}] = \text{"早上"}$ 且 $C[\text{"state"}]$ 为空，系统将根据中文习惯，隐式设置 $C[\text{"is\_greeting"}] = \text{True}$，并推断 $\text{"state"} = \text{"好"}$，以确保生成“早上好”而非仅“早上”。

通过这种结构化表示，无论原始手语序列的词序如何混乱，语义组合的核心要素都能被准确提取。

\section{基于规则的自然语言生成与置信度校准}
自然语言生成（NLG）阶段采用一套\textbf{启发式语义组合规则集合} $R$，实现从结构化语义 $C$ 到最终自然语句 $Exp$ 的映射。

\subsection{高优先级语义组合规则 ($R$)}
每条规则 $r \in R$ 都是一个三元组 $(Pr, Gr, \Delta Conf_r)$：

\vspace{0.5em}
\noindent $Pr$：规则条件，是基于上下文 $C$ 的逻辑判断（使用 $\lambda$ 函数实现），其逻辑判断的复杂度体现了对模糊语义的捕捉能力，如判断 $(C[\text{"time"}] \land C[\text{"gratitude"}] \land \neg C[\text{"pronoun"}])$。

\noindent $Gr$：生成函数，根据匹配的语义槽生成精确的中文语句。

\noindent $\Delta Conf_r$：置信度加成值，用于体现该组合意图的强弱。强组合（如“早上好，谢谢你”）被赋予较高的 $\Delta Conf_r$，以保证在竞争规则中获得最高的优先级。

系统首先匹配具有最高 $\Delta Conf_r$ 的规则，若匹配成功，则以此规则生成基础表达。

\subsection{对话语境与自然语言增强}
为了使生成的语句具有对话连贯性和情感色彩，系统引入了两个动态增强机制：

\vspace{0.5em}
\noindent\textbf{语境适配模板}

系统维护一组针对不同对话场景（如 \texttt{first\_greeting}、\texttt{response\_to\_thanks}、\texttt{formal\_setting}）的语境模板。在生成语句后，系统有概率（例如 20\%）使用当前语境下的预设模板进行替换或补充，确保生成的语句符合当前的对话流程，而非孤立的翻译。

\vspace{0.5em}
\noindent\textbf{情感修饰与敬语}

在语句末尾随机添加语气词（如“呀”、“呢”），或在正式场景（\texttt{formal\_setting}）下将人称代词“你”替换为“您”，以实现语言的自然性和情感的丰富性。

\subsection{双重验证与置信度校准}
最终的输出表达式 $(Exp, Conf)$ 采用双重验证机制，结合了规则驱动的置信度和深度学习模型意图分类的置信度。其中，$Conf_{base}$ 为初始基础置信度（如 0.7）：

\vspace{0.5em}
\noindent\textbf{规则置信度}

$Conf_{base} + \Delta Conf_r$ 构成了基于语义逻辑的置信度，它反映了规则对当前序列的拟合程度。

\vspace{0.5em}
\noindent\textbf{模型置信度}

$Conf_{model}$ 是由轻量级意图分类模型（如 GlobalAveragePooling1D + Dense）对预处理后序列预测出的意图概率。

\vspace{0.5em}
当规则置信度与模型置信度都较高时，系统采取平均值增强最终置信度，提高了表达的可靠性。只有当 $Conf_{final}$ 超过预设的模糊阈值（例如 0.4）时，系统才确认表达的有效性并输出结果，否则执行 \texttt{fallback\_generation} 或返回“无法识别”，从而确保了系统在不确定情况下的稳健性。

\section{本章小结}
本章针对手语识别任务中普遍存在的“孤立词拼接”与“自然语言表达”之间的语义鸿沟，提出并实现了一套完整的模糊语义识别与后处理框架。

该框架创新性地将手语识别输出视为一种具有高模糊性的视觉词汇序列，通过三阶段流水线——\textbf{语义保留的序列预处理}、\textbf{结构化的隐式意图推理}、以及\textbf{基于启发式规则与深度学习双重校验的自然语言生成}——有效地解决了手语表达中的冗余、无序及多义性问题。

特别是，本研究引入的\textbf{双重置信度校准机制}，在保证规则生成的语言学规范性的同时，利用数据驱动的模型概率进行验证，显著降低了误识别风险。这一机制不仅提升了系统输出语句的通顺度与逻辑性，更赋予了机器理解对话语境与情感色彩的能力，实现了从“信号感知”向“语义认知”的关键跨越，为构建真正实用化、人性化的手语交互系统提供了坚实的技术支撑。
%%%%%%%%%%%%%%%%%%%%%%%%  参考文献  %%%%%%%%%%%%%%%%%%%%%%%%


% 即使正文中没有引用，也强制打印 .bib 文件中的所有文献
% 等你真正开始写论文并使用了 \cite{key} 后，可以删掉这行
\nocite{*}

\begin{references}
    % 确保 references.bib 文件在同级目录下
    \bibliography{references}
\end{references}

%%%%%%%%%%%%%%%%%%%%%%%%%  致谢  %%%%%%%%%%%%%%%%%%%%%%%%%

\StartAcknowledgements
感谢指导老师徐韬的悉心指导，以及第7组全体成员的共同努力。

\end{document}